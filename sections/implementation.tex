
\section{Implementation}


\subsection{Denoising Diffusion Probabilistic Model}

Denoising Diffusion Probabilistic Model 也稱作 DDPM，是一種利用不斷地加入噪音到圖片中，並且學習如何去噪的模型，加入噪音的步驟叫做前向過程，去噪的步驟叫做反向過程，而這個過程中會經過許多的步驟，每個步驟都會加入一點點的噪音，最後會得到一個非常模糊的圖片，然後模型會學習如何從這個模糊的圖片中，一步一步地恢復成原本的圖片，由於我們可以掌握每一步驟加入的造音是什麼，所以有 groundtruth 可以學習，所以這個過程可以被訓練成一個去噪的過程。

實際訓練步驟如下：

\begin{itemize}
    \item 從所有圖片中抽取一張圖片，稱作 $x_0$
    \item 然後從 1 \~ t 中選擇一個數字，稱作 t，這裡我設定 t 為 1000 步。
    \item 然後生成一個噪音的圖片，接著計算真實圖片與噪音圖片，在給的步數 t 時，兩者的混合比例。
    \item 接著把 noise 的圖片與 t 與 condiaion embedding 一起送入模型，模型會預測這個圖片在 t 時的 noise 是什麼。
    \item 由於我想要準確的預測噪音，所以這裡是一餓回歸任務，回歸每個圖片的每個座標的噪音數值，所以我使用 MSE loss 來協助模型學習。
    \item 接著計算梯度，然後更新模型。
    \item 重複上述策略直到 epoch 設定數量結束。
\end{itemize}












\subsection{Model Architecture}

由於需求是按照給定的 label 來生成圖片，因此要考慮 label 的資訊如何融入模型中。

這裡我使用 diffusers ，來自 Hugging Face 的 library 創建 conditionalDDPM，主要架構使用一個 U-Net 的架構，首先我會把 conditional 的資訊透過一層 fc 編碼成 embedding ，以及把 step 的 t 編碼成一個 embedding，並且把這兩個相加，接下來 diffusers 建構的 Model 中，每個 layer 會有兩個輸入，一個是來自上一層的 UNet 的輸出，另一個則是來自於我的 embedding，我設計的 embedding 輸入到每個 layer 之時，每個 layer 會在準備一個 fc 層，把 embedding 轉換成適合的維度，接著我考慮從上一個 layer 來自的輸入，會先經過主架構，也就是 U-Net 的 CNN，然後接著把這兩個輸入相加，當作這個 layer 的輸出。

接著考慮一個案例，就是一個貓的尾巴與頭在圖片上的距離可能會很遠，但其實彼此是有關聯的，所以這裡我在比較高層次的 layer 中，加入一個 attention 的機制，來讓模型學習到這個關聯性，因為比較高層次的 layer 被相信帶有比較多的語意訊息，所以這裡我在比較高層次的 layer 中，加入一個 attention 的機制，來讓模型學習捕捉全局特徵和上下文。

那為什麼不在所有的 layer 都加入呢？ 因為淺層的網路需要先專注在 local 的特徵上面，先建立對於 local 的理解，所以 attention 的機制可能只是浪費計算資源，並不會帶來多少效果，所以只在比較抽象語意的地方加入。




\subsection{Noise Schedule}
雖然我可以不斷地加入噪音，但是對於資源的調度來說非常吃力，為了計算第 1000 步，我需要把前 999 步的資訊都保留，這樣的計算量非常大，所以這裡我使用 squaredcos\_cap\_v2 來計算如果從最純淨的圖片開始，經過 t 步後，會變成什麼樣子，他跟噪音的相互權重是多少比例，這樣就可以減少計算量，並且保留足夠的資訊。

在原始的論文中，是使用線性的方式設計噪音與真實圖片的混合比例，但是接下來的研究發現，噪音的曲線對於結果的學習很重要，想像一個圖片他的訊號包含高頻與低頻，如果每一個步驟都加入一樣程度的噪音，高頻細節訊號很快就被噪音訊號蓋住，使得模型尚未對高頻細節做充分的理解，所以這裡使用 squaredcos 的曲線來設計噪音與真實圖片的混合比例，這樣可以讓模型在學習的過程中，慢慢加入噪音，讓模型有更多時間，好好的學習細節。











\subsection{Classifier Guidance or no?}

這裡助教有提供一個訓練好的分類器，讓同學可以判斷訓練出來模型的表現，另外同學也可以選擇使用這個分類器來當作引導，讓模型可以有執導的訊號，更快的收斂，但是這會讓模型有分類器的偏見，所以我的信念裡，是希望模型可以自己學到圖片的架構，而不是像是填鴨式教育，所以這裡我選擇不使用分類器。




